{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLfwM659x_NW"
   },
   "source": [
    "# Predict Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkLLf-YSAdEs",
    "outputId": "4b9c0749-591d-4dec-9763-11b05cb38a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 29 03:48:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRVvLCGXAe7L"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/shopping')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "!pip install transformers datasets\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvmb0hXvATAQ"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "from typing import Callable, Dict, List\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIe1Y75TATAS"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njB3IC81ATAT"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "VALID_SPLIT = 0.1\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "DR_RATE = 0.3\n",
    "WARMUP_STEPS = 500\n",
    "WEIGHT_DECAY = 0.01\n",
    "METRIC = 'accuracy'\n",
    "\n",
    "LABELS = [1,2,4,5]\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h00avBx4ATAW"
   },
   "outputs": [],
   "source": [
    "def tokenize(model_path: str) -> Callable[[Dataset],BatchEncoding]:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, problem_type='multi_label_classification')\n",
    "    clear_output()\n",
    "    return lambda examples: tokenizer(examples['reviews'], max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "\n",
    "def one_hot(examples: Dataset) -> Dict[str,np.ndarray]:\n",
    "    return {'labels':np.eye(len(LABELS))[label2id[examples['target']]]}\n",
    "\n",
    "def preprocess(data: Dataset, model_path: str, labeled=True) -> Dataset:\n",
    "    encoded = data.map(tokenize(model_path), batched=True, remove_columns=['id','reviews'], load_from_cache_file=False)\n",
    "    encoded = encoded.map(one_hot, remove_columns=['target'], load_from_cache_file=False) if labeled else encoded\n",
    "    encoded.set_format('torch')\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGnmTZ9PATAX"
   },
   "outputs": [],
   "source": [
    "def model(model_path: str) -> AutoModelForSequenceClassification:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "        problem_type='multi_label_classification',\n",
    "        ignore_mismatched_sizes=True,\n",
    "        num_labels=len(LABELS),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,)\n",
    "    clear_output()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAcmgIfrx_Ne"
   },
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "01e454d23a0f48ffbf46bd3046c1beae",
      "6784eb3dafdc4d2b92fe984e7557fc12",
      "05df7aa07b6647629481cb008df4797e",
      "98567bd00a464aa39b446bb627e631bb",
      "6ed4ec87157246519149184750415117",
      "81eff09b3afe4d6aa4eacc78580a0cc5",
      "1fc64d3f02dd4405ae0fdb77a4e9b542",
      "88844387c9474f40b90ae1e20d20197d",
      "71f542b5dfc741d1af6c5671411ed197",
      "aa073623035f4c8692458c00dd8cc27d",
      "520cfebb365c4e7e8097b89d2a99fa55",
      "34e7a47a14264ae6aeb596f58597c75e",
      "0bc27e998c52471c9f6a7e576f9c5081",
      "74d464e44b0f4eb1afe68f4a674f834f",
      "670482cd27e7467a9be6a906a9a11b07",
      "472b4bc511f241c4bac48e53f124b3bc",
      "df7b07ec24aa4d4a9e887ae530de3036",
      "ee60009e6abe44caac82c59237f8c5d8",
      "af795ed40fcf40939a746c20a32971b6",
      "0c3353596e984408a07ee4a31b7d20f1",
      "10ad5dc6b18e41299ea08c549f17f558",
      "183469a5b65c4c15bc24a07b0a21fee8",
      "785ea04913a14bcaa62f52668c3cc908",
      "1bdefbadb67e46599eff46f1cd7b0459",
      "953bda39cda442c99e3ac774e15d2c2d",
      "fa517397faa64a2abf1638b11f6c0c84",
      "ed8749cf51294966a349aced4cd00dbd",
      "8805be53f7844baf9ff76636400851d3",
      "370f0554aba4429a8d6c38ddf6828e3e",
      "58ef7d0cc432421e8142220d45abd12d",
      "140f83d74fda4d7cbfe4e3cc4fdb1c52",
      "cfb3185051d94fc9963a401ac1e26f48",
      "64adf5e167e44674817f8bad3e30b46e",
      "d7795af756bc4348aea0f690db646a4d",
      "10a04bb0d9134c558c9dbd397b2e63d4",
      "8147d089dd5b4af8a0bf67fb54b76464",
      "edc997c775e44f61847bea7f9977ae45",
      "5b4c3cedb89e4f979f98c8c71aefc048",
      "7311d4bcc50949809cf24c83a6e02249",
      "49b0d4bb95fb4225b4337c8650603dcb",
      "5600c84a12204b27afc855b6f51cf738",
      "972b1f2bc4194794bbf5e86c7f7f5be7",
      "47c734a9803d4c37ad3cfdf0bacfbb1a",
      "956338a35cfd4fda98c2590159ef3d72",
      "b0c4ee8cb61540c59def70d25bb798a8",
      "e1c86a4e275d4c489249ea4b7510af52",
      "d3ae57ec501545668f6041cfeb7ef193",
      "1efb48eca30a4c26b88fc44fb20e6b56",
      "58d00bb595d841db99946e38b74ee632",
      "9d6818897cbc45deaa82450f979d4303",
      "e323e7c93b564b01b1aa97b62de267ca",
      "3996a586d5914997a766c109cda742c6",
      "fa14d9d1886a41fc986ae803e986235d",
      "86e80b6826734a7390961c997af365c5",
      "a6186ac6aead40d29cadc5a0fd1e9a37",
      "ae2b2914a31b4473bdabb413ebf7818b",
      "97545c77bcd84a02b27c4bc9a9900b46",
      "1183d66db2f449b5a33d37b06faa119d",
      "2067531e09794f9cb588cee4a2aece1b",
      "48489cc390224e2abadbe63e1f5af5e1",
      "81a4f5328c464565a72236495426c906",
      "9daeff6d4bf04147ac3246e23b89ceb9",
      "d97b3620d0fd454fae9b8d5986fa26ca",
      "74dde8395d9c4917b3590bbcab502195",
      "5ee22fabf32145d2b5c97cf7e38a626f",
      "aa5540205c5a475f82d68b33548649e4",
      "ba48ce549a06468d833496f692b335e3",
      "6f6946543dda40adb0251a0e95ee403f",
      "c049e5d22b154bbb91805e1c20350580",
      "089a182e361f4f7194744ffb4521190c",
      "9668a07d98e641ff8aa7875048c55dd2",
      "48fa330dc145437b956227eda110bc82",
      "7759661c6f7f494eb817ac897630400c",
      "fcff32fca38a43a491a38f19befc194f",
      "0c702f379cb74c6c8c505dcf11ae8fae",
      "81bd7af7fcaa47c7beb3d096ef59c770",
      "c53bb8515e8840fcbb668883a44105d7",
      "7ba6b09a40834e29947b9ca5e68b766e",
      "1ec367dac7484af59e569217e8867d96",
      "aabe99cb3d204efeb9350db805bc32e7",
      "ac7ef237440144a99294a53ba02ad3ae",
      "8de1c2adfb0445b29c247ec38e45e761",
      "ff3110ea75b545878a5ea88d7ef9162f",
      "9682b8ed17ca49c6b09c9824eed6559a",
      "574787064bd348f19fdf369b5fcc7fdd",
      "73f9bd2d3db942678691326ee65fa619",
      "b65e43df279d493784db7a9dc0190bf4",
      "39dcbee03671425598e1f11619ce13fc",
      "76ff57c4112d41a5bc890d623349d469",
      "d84eb10a8cdc49289b699737c66dd470",
      "030b088296c94e999bbadf8a6a43824f",
      "db67438bd5b948fd841e828d0f484586",
      "cd1e1e07f1a44c09a021118714f56a0c",
      "5c6bf092d635472084251d34a5fffe8c",
      "5314a9d03314416f8b0512f3b57e8e61",
      "0de1c3bb26924c85bc484060140b7648",
      "44af470fcd8648bd9d0652969b3f03e2",
      "2c36ab2e5b4c4527b10d1824867406f7",
      "6ce6f611952b4dd98806314a964a502d",
      "c0b9c7eeee2a4ff2a6bfe6e896aa01d7",
      "a5ee7598547544e98c4dced74a2ce6b8",
      "83bd3590e14844408afe867403a1895e",
      "a8dfe32dc53d4ed2be2fa7a4866e6402",
      "87abf8f347ea4bc38a203b516c35f110",
      "4f200d166f8f4bcebfb31092e0d03223",
      "e2c86d25ba684cacb12045b73c23397c",
      "ddfd946569204f718058e619facd3b50",
      "c5a95abaa1d24cd58858382d73fe0e9d",
      "e3b5e9b0faa04b02be6090213e4461b7",
      "bc55fa7a6dc845cfb1a13fa4307e85c9",
      "e2c5d17f0bbd484eab49e7519714eff8",
      "c07c701fa5724c888887ccff8aa21be8",
      "24421d7d5ad04ee98e74c269c593cf0b",
      "db3de749a80948b480f7b341b80c0f67",
      "403663d78319480188875208a1aa2be8",
      "c4d1c28d557d4834b0d5c6f98ead6836",
      "142d92580e02406f950ae1179fe48399",
      "1caa3823e4614a9386fd968171340137",
      "6c33bc37d1724d48a3add8c7c06fdd22",
      "06e83eacb556414cbba30f8a5dec7e79",
      "a91cbd92b5c340168f12ac585b7f70a0",
      "6b5c490db1bd4bbd948a4aff69cc4f09",
      "d73db8d1a43c4ab790c07b567762535e",
      "a643407b8ef346459304d94a313a0b48",
      "7c66653c3050493eb95a18e6f7207365",
      "fd8ce6ca3e4f44a5a86810294d88ea44",
      "4b5c805a9470428786c47778c6ef5c1b",
      "7da3eae10d1d4fb593869a4d00c80f4d",
      "cfccc810612d4135a2effd73f37fd926",
      "9a6f8327d5de4abb8dc63d2ef8f25b42",
      "39aaad5cad324232b032870bda34a7ff",
      "1c0eacb237d44952ab2a40ba97d88904"
     ]
    },
    "id": "0q2Zf7C4ATAV",
    "outputId": "ee992700-173e-4781-cef3-b4d652d50ae0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL_PATH = 'jaehyeong/koelectra-base-v3-generalized-sentiment-analysis' # KoELECTRA\n",
    "MODEL_PATH = 'klue/roberta-large' # RoBERTa\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_vanilla_dataset = load_dataset('csv', data_files='./data/test.csv', split='train')\n",
    "test_vanilla_dataset = preprocess(test_vanilla_dataset, MODEL_PATH, labeled=False)\n",
    "test_vanilla_loader = DataLoader(test_vanilla_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_cleaned_dataset = load_dataset('csv', data_files='./data/test_cleaned.csv', split='train')\n",
    "test_cleaned_dataset = preprocess(test_cleaned_dataset, MODEL_PATH, labeled=False)\n",
    "test_cleaned_loader = DataLoader(test_cleaned_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "clear_output()\n",
    "len(test_vanilla_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuHACqCtx_Nf"
   },
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pmf0fOrzeJa"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'koelectra_epoch10'\n",
    "output_dir = os.path.join('./saved/models', MODEL_NAME)\n",
    "submission_vanilla_dir = os.path.join('./data/samples', MODEL_NAME+'_vanilla')\n",
    "submission_cleaned_dir = os.path.join('./data/samples', MODEL_NAME+'_cleaned')\n",
    "if not os.path.exists(submission_vanilla_dir):\n",
    "    os.mkdir(submission_vanilla_dir)\n",
    "if not os.path.exists(submission_cleaned_dir):\n",
    "    os.mkdir(submission_cleaned_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp76-vDxx_Ng"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta_epoch10'\n",
    "output_dir = os.path.join('./saved/models', MODEL_NAME)\n",
    "submission_vanilla_dir = os.path.join('./data/samples', MODEL_NAME+'_vanilla')\n",
    "submission_cleaned_dir = os.path.join('./data/samples', MODEL_NAME+'_cleaned')\n",
    "if not os.path.exists(submission_vanilla_dir):\n",
    "    os.mkdir(submission_vanilla_dir)\n",
    "if not os.path.exists(submission_cleaned_dir):\n",
    "    os.mkdir(submission_cleaned_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b3kvQ3J0CEv"
   },
   "outputs": [],
   "source": [
    "checkpoint = './saved/models/roberta_large/checkpoint-1408'\n",
    "submission_dir = os.path.join('./data/samples', MODEL_NAME)\n",
    "if not os.path.exists(submission_dir):\n",
    "    os.mkdir(submission_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3RI3wnYx_Ng"
   },
   "source": [
    "## Predict Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Chm7_Mj0x_Nh"
   },
   "outputs": [],
   "source": [
    "def predict_proba(checkpoint: str, dataloader: DataLoader) -> List[List[float]]:\n",
    "    pretrained_path = os.path.join(output_dir, checkpoint)\n",
    "    pretrained_model = model(pretrained_path).to(device)\n",
    "    proba = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for samples in tqdm(dataloader):\n",
    "            for key in samples.keys():\n",
    "                samples[key] = samples[key].to(device)\n",
    "            outputs = pretrained_model(**samples)\n",
    "            proba += F.softmax(outputs.logits).tolist()\n",
    "\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "632370a0e9e8465ea3c5242acbe82abd",
      "d2f92d19e6434da5a6569c3507ea1b49",
      "bd471332b7924e40b3ccfb03c95904d0",
      "adf0b2db207b40c08224e28c015e88db",
      "8a39db85fa764211b8ff6aa6a4b98389",
      "4f83200165914959a026df70f3a9ba1a",
      "17f96f12fc25471ebe7840468799dc44",
      "eeac1472386d4fc9982782d572dcf37e",
      "bd79eb6cc90e4219a46c72710255e552",
      "9cb575a91fa946e4acf4532302467519",
      "204fbd979fa849a39e991b0ef80fa890",
      "6584ce2422ab478f96f253c20c9a53f0",
      "2f6763b1db6545a380be9affacbd6913",
      "ac8db19ccd17487ea88d588ed7c3ed06",
      "f4bb9a00e45e481f8ddf887a7f29060b",
      "9246a91b17c443efa586ef400988c2bf",
      "44afe05ba5e5451e960d1f64011dd570",
      "ea08ab8936114dca8ad95966b18cef22",
      "f7f337159f504329a58ddcf25440cb3c",
      "d4b52c3cb8384c5681829bb200ebbe45",
      "67c816a52ca5412b979e1f395177ab6e",
      "f06ea760e1674642b09b00c0f85ec688",
      "ebae24d581d84a33a917e983a76f7feb",
      "7f7158453b564e989956030c3185463c",
      "72fd09534a7545e9bd3837b770cb32af",
      "e8b494532c6846fea44516d9cec6bedf",
      "f00e3362e7e94b3485eb9b7d0167592b",
      "aabbd38893a048beacb5cf54f172b56b",
      "f43772bc16084d22be7b7cb1f11d8fb9",
      "707cf1f8ff744e7a9d535e58f5e15d87",
      "48559ac8190941c994239a16b4970f88",
      "62cb8e572bf94a808bd03dbd03e20285",
      "62219cefd3864c6aaa8c5572035b57cf",
      "1f913f25b5084906b5687d1f6a576a7c",
      "53fd2b8cbfed4e8d832811308f4e9de8",
      "e0567f3f89c74f2aa536dbea5ded981c",
      "51d7f673bb82442e9737cab9f775a167",
      "212e6723bd7e4fb790ad19444efb95da",
      "81104580ad554fa983d228e6a336a37d",
      "be6a3b9467474390a906775d2801479e",
      "5187c287a0d84c0b871ea780f6dc0488",
      "8d736745c1dd4dcf81c18c1897468c4f",
      "b90bf21641504d3bacf0fffccc5ce6e3",
      "392a5cbc15e441a68e3e6b7ff983e617",
      "1c170f40462a4d8a86e3f9ba2ee8c732",
      "136eb6112a114f90af482901fbec01c9",
      "fc75942827454fae864f9c8253dff702",
      "346e7131213248b68e38e237d41ccd96",
      "f1e9ea19f4f142049adf3242d57deacc",
      "bfd60774b90245d99f4324b501d3e693",
      "79ae15043c0a47389c03887a402c9a80",
      "24b6dbce65674649bf46369cd794fae9",
      "3a1562ab2dae471fb7d0250b13db03c8",
      "4f72e44de3d7440da935e134567eae02",
      "35ba6ca9a66f4601b265fb545049b7e5",
      "a5afaaafed9244dbb516d56cb29ed680",
      "7f62e8d105584891ae7dca2ed94bda21",
      "590b516c63ab400482734be2a62f5bc0",
      "987757f35dda4e3ea41fda10762ba405",
      "6006cab912984e4db09b57fc1ff3fc28",
      "206ad8420d4e4476922f677030ab7f2e",
      "44b8498520bf46189453877ff42b5d8b",
      "9c62b1e44a774d299ad543eb8704e245",
      "7ab2e7f6956843d7ae05e8bc6cb29b54",
      "30b6ab6024c94498ae77b5ea9ba1b0ad",
      "18660e7a46444bd582cbb21e3bf979ef",
      "98346fa0230f4f3f8d1cb6abdce8f430",
      "0ccb048c7d1548b7918547e776f81480",
      "3d44f400a5c4465d89c51734c957efe8",
      "fb49cdf0d6a3410a965a311526a87d54",
      "1aa0689cb09642f6b3f1f3dd3157e50a",
      "80b4eee09b534c10aef738f92f056468",
      "173a85266d8c436bbf0a42dc8dc5410a",
      "9406cc4cd3704bd4a0c7e0a1728176cb",
      "6aac150e05dc4c75ac7f3187ebcd7e1c",
      "a4bb84085cce4b68a3380bef60bc3a7c",
      "f050c2129b4b4486b491b574b077af57",
      "9102719c8b0a4528b3cc2d17a928c567",
      "4bdd0fbccb6340d287d0ae378cf6dfc9",
      "c3410db843be4271a17cc1e1b31d0d7b",
      "a1c804ca367f4452a3409cdba5aeb85d",
      "43f64465da24477abec8cee5169fef57",
      "37d6ef923ed849239d57ede0ec905fa9",
      "04dc88f5c459466faa10eb91785da0d8",
      "12e07821a922419b80ee12716bfb34a5",
      "21ab1e0834af41e3b669088299b8099b",
      "a026fe7578b441b0815a3c3d73c7ad83",
      "95fe3dc6a1f84db083b9c1fa353bda9a",
      "eaf4b326ab0641368b74c4eda403aaa2",
      "c7ccd4419c324aac89aac112807dd613",
      "72bdb17dc3c34772940d5feedb06f05e",
      "e706128228f64ed5b5df888be989d4f8",
      "bdbfba5e37a844d5979afde31514896b",
      "91953fa03fce466fb15b6d688c7e43d3",
      "dd134125294b441483cc6335e988b7dd",
      "eb8edac367c248db81827de8573feb74",
      "bdca48d12f3b4abcacbd1ed963c3ebd4",
      "f8cf11a4bb7047eb8a532ec61e52a6b3",
      "1751c47acd384a53adc1284f47c1150f"
     ]
    },
    "id": "bliY4YOQx_Nh",
    "outputId": "f8ce41d5-41ab-4cef-e317-df2ec7d5136c"
   },
   "outputs": [],
   "source": [
    "for i,checkpoint in enumerate(sorted(os.listdir(output_dir)), start=1):\n",
    "    proba = predict_proba(checkpoint, test_vanilla_loader)\n",
    "    proba = pd.DataFrame(proba, columns=LABELS)\n",
    "    proba.to_csv(f'{submission_vanilla_dir}/epoch{i}.csv', index=False)\n",
    "\n",
    "for i,checkpoint in enumerate(sorted(os.listdir(output_dir)), start=1):\n",
    "    proba = predict_proba(checkpoint, test_cleaned_loader)\n",
    "    proba = pd.DataFrame(proba, columns=LABELS)\n",
    "    proba.to_csv(f'{submission_cleaned_dir}/epoch{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J64A2N6V1Kpd"
   },
   "outputs": [],
   "source": [
    "proba = predict_proba(checkpoint, test_vanilla_dataset)\n",
    "proba = pd.DataFrame(proba, columns=LABELS)\n",
    "proba.to_csv(f'{submission_dir}/vanilla.csv', index=False)\n",
    "\n",
    "proba = predict_proba(checkpoint, test_cleaned_dataset)\n",
    "proba = pd.DataFrame(proba, columns=LABELS)\n",
    "proba.to_csv(f'{submission_dir}/cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('mldl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ae205601b6d906014fa7892090616f7e1469eb0aa86f06d2d1803a695f1eb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
