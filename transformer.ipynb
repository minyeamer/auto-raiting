{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('korean')\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "import googletrans, random, re\n",
    "from typing import List\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviews</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>조아요 처음구입 싸게햇어요</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>생각보다 잘 안돼요 매지 바른지 하루밖에 안됐는데ㅠㅠ 25천원가량 주고 사기 너무 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>디자인은괜찮은데 상품이 금이가서 교환했는데 두번째받은상품도 까져있고 안쪽에 금이가져...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>기전에 이 제품말고 이마트 트레이더스에서만 팔던 프리미엄 제품을 사용했었습니다. 샘...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>튼튼하고 손목을 잘 받쳐주네요~</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            reviews  target\n",
       "0   0                                     조아요 처음구입 싸게햇어요       2\n",
       "1   1  생각보다 잘 안돼요 매지 바른지 하루밖에 안됐는데ㅠㅠ 25천원가량 주고 사기 너무 ...       1\n",
       "2   2  디자인은괜찮은데 상품이 금이가서 교환했는데 두번째받은상품도 까져있고 안쪽에 금이가져...       2\n",
       "3   3  기전에 이 제품말고 이마트 트레이더스에서만 팔던 프리미엄 제품을 사용했었습니다. 샘...       2\n",
       "4   4                                  튼튼하고 손목을 잘 받쳐주네요~       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(data=train, x='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "- 라벨 간 불균형을 조정하기 위해 번역을 활용한 데이터 증강기법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 한글 > 영어(,프랑스어,일본어,중국어) > 한글 역번역\n",
    "- 결과가 만족스럽지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생각보다 맛이 별로라\n",
      "내가 생각했던 것보다 맛이 좋습니다\n",
      "--------------------------------------------------\n",
      "배송도 빠르고 눈썹은 괜찮은데 글로가 정말 별로네요ㅜ\n",
      "배달은 빠르고 눈썹은 괜찮지 만 글은 정말 좋습니다.\n",
      "--------------------------------------------------\n",
      "실제 보고 인터넷으로 구매한건데 정품이 아닌건지 유난히 가방이 가로가 길어요;; 여자가 들기엔 안예쁜것 같아요. 남자 운동 가방으로 그나마 쓸것같네요....\n",
      "사실, 나는 인터넷에서 그것을 샀지 만 가방은 비정상적으로 길다. 나는 그것이 여자라고 생각하지 않는다. 나는 그것이 남성 운동 가방이 될 것이라고 생각한다 ....\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import googletrans\n",
    "\n",
    "translator = googletrans.Translator()\n",
    "\n",
    "for i in [10,20,30]:\n",
    "    original = train[train['target']==1]['reviews'].iloc[i]\n",
    "    translated = translator.translate(original, dest='en').text\n",
    "    result = translator.translate(translated, dest='ko').text\n",
    "\n",
    "    print(original)\n",
    "    print(result)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NLPAUG 동의어 변환\n",
    "- WordNet에서 한글 소스가 존재하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red malus pumila']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "aug = naw.SynonymAug()\n",
    "text = 'red apple'\n",
    "aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 역번역 중간에 NLPAUG 적용\n",
    "- 더욱 다른 의미로 변환되어 데이터의 품질 저하 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생각보다 맛이 별로라\n",
      "정보 기술은 생각보다 맛이 좋습니다\n",
      "--------------------------------------------------\n",
      "배송도 빠르고 눈썹은 괜찮은데 글로가 정말 별로네요ㅜ\n",
      "배달은 빠르게 살고 눈썹은 괜찮지 만 글은 진정한 전문가입니다.\n",
      "--------------------------------------------------\n",
      "실제 보고 인터넷으로 구매한건데 정품이 아닌건지 유난히 가방이 가로가 길어요;; 여자가 들기엔 안예쁜것 같아요. 남자 운동 가방으로 그나마 쓸것같네요....\n",
      "사실, 나는 사이버 공간에서 그것을 뇌물을 뿌리고 가방만이 비정상적으로 멀리 떨어져 있습니다.나는 그것이 여자라고 생각하지 않습니다.정보 기술의 크로크는 남자와 같은 운동 그립이라고 생각합니다....\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [10,20,30]:\n",
    "    original = train[train['target']==1]['reviews'].iloc[i]\n",
    "    translated = translator.translate(original, dest='en').text\n",
    "    translated = aug.augment(translated)[0]\n",
    "    result = translator.translate(translated, dest='ko').text\n",
    "\n",
    "    print(original)\n",
    "    print(result)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 토큰 단위로 역번역\n",
    "- 상대적으로 나은 결과가 확인되지만, 변환 속도가 매우 느린 단점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ko_tokenize(sentence):\n",
    "    okt = Okt()\n",
    "    sentence = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','',sentence)\n",
    "    tokenized = okt.morphs(sentence, stem=True)\n",
    "    return [word for word in tokenized if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['생각', '보다', '맛', '별로', '라']\n",
      "['생각', '하다', '보다', '맛', '그만큼']\n",
      "--------------------------------------------------\n",
      "['배송', '도', '빠르다', '눈썹', '은', '괜찮다', '글로', '정말', '별로', '요', 'ㅜ']\n",
      "['배송', '하다', '빠르다', '눈썹', '은', '괜찮다', '진짜', '에야', '디', '흐', '느낌']\n",
      "--------------------------------------------------\n",
      "['실제', '보고', '인터넷', '한', '건데', '정품', '아니다', '건지다', '유난히', '가방', '가로', '기다', '여자', '들다', '기', '엔', '안', '예쁘다', '남자', '운동', '가방', '그나마', '쓸다']\n",
      "['진짜', '보고서', '인터넷', '진실하다', '아니다', '떠나다', '비정상', '적', '가방', '너비', '기', '다', '여성', '잡고', '에너지', '아니다', '예쁘다', '남성', '운동', '가방', '기부', '스', '위프']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [10,20,30]:\n",
    "    original = ko_tokenize(train[train['target']==1]['reviews'].iloc[i])\n",
    "    translated = [translator.translate(token, dest='en').text for token in original]\n",
    "    result = [translator.translate(token, dest='ko').text for token in translated]\n",
    "    result = ko_tokenize(' '.join(result))\n",
    "\n",
    "    print(original)\n",
    "    print(result)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Word2Vec를 활용한 유사어 변환\n",
    "- 원본 문장과는 전혀 다른 의미가 되어버리지만, 전반적인 감정 수준은 유지되는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "num_features = 300\n",
    "train_data = [ko_tokenize(data) for data in train[train['target']==1]['reviews']]\n",
    "model = Word2Vec(sentences=train_data, vector_size=num_features, window=5, min_count=1, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['생각', '보다', '맛', '별로', '라']\n",
      "['아니다', '서', '완전', '고']\n",
      "--------------------------------------------------\n",
      "['배송', '도', '빠르다', '눈썹', '은', '괜찮다', '글로', '정말', '별로', '요', 'ㅜ']\n",
      "['오다', '눈썹', '아니다', '는', '완전', '느리다', '상품', '이다', '글로']\n",
      "--------------------------------------------------\n",
      "['실제', '보고', '인터넷', '한', '건데', '정품', '아니다', '건지다', '유난히', '가방', '가로', '기다', '여자', '들다', '기', '엔', '안', '예쁘다', '남자', '운동', '가방', '그나마', '쓸다']\n",
      "['유난히', '말다', '걸', '오다', '시', '고', '되다', '비싸다', '아니다', '막', '적', '는', '연결', '않다', '나오다']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [10,20,30]:\n",
    "    original = ko_tokenize(train[train['target']==1]['reviews'].iloc[i])\n",
    "    result = list()\n",
    "    for token in original:\n",
    "        synonym = model.wv.most_similar(token)[0]\n",
    "        result.append(synonym[0] if synonym[1] > 0.95 else token)\n",
    "    result = list(set(result))\n",
    "\n",
    "    print(original)\n",
    "    print(result)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec와 역번역을 활용해 Augmentation을 수행하는 함수 정의   \n",
    "전처리 과정에서 해당 함수를 활용해 평점 별 데이터 수를 10000개로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ko_tokenize(sequence: str):\n",
    "    okt = Okt()\n",
    "    tokenized = okt.morphs(sequence, stem=True)\n",
    "    return [word for word in tokenized if word not in stop_words]\n",
    "\n",
    "def get_synonym(word: str, model: Word2Vec, match_rate: float):\n",
    "    pred = model.wv.most_similar(word)[0]\n",
    "    return pred[0] if pred[1] > match_rate else word\n",
    "\n",
    "def get_translated(word: str, translator: googletrans.Translator):\n",
    "    try:\n",
    "        en_translated = translator.translate(word, dest='en').text\n",
    "        kr_translated = translator.translate(en_translated, dest='ko').text\n",
    "        return kr_translated\n",
    "    except:\n",
    "        return word\n",
    "\n",
    "def unique_matrix(matrix: List[List[str]]):\n",
    "    matrix = list(set([' '.join(array) for array in matrix if len(array) > 0]))\n",
    "    return [str(array).split() for array in matrix]\n",
    "\n",
    "def word2vec_aug(sequences: List[str], num_aug: int, num_features=300) -> List[List[str]]:\n",
    "    num_aug = num_aug - len(sequences)\n",
    "    tokenized = [ko_tokenize(sequence) for sequence in sequences]\n",
    "    model = Word2Vec(sentences=tokenized, vector_size=num_features, window=5, min_count=1, workers=4, sg=0)\n",
    "    translator = googletrans.Translator()\n",
    "\n",
    "    augmented, match_rate = list(), 0.95\n",
    "    while len(augmented) < num_aug:\n",
    "        synonyms = [list({get_synonym(token, model, match_rate) for token in sequence}) for sequence in tokenized]\n",
    "        translated = [ko_tokenize(' '.join([get_translated(token, translator) for token in sequence])) for sequence in tokenized]\n",
    "        augmented = unique_matrix(augmented + unique_matrix(synonyms) + unique_matrix(translated))\n",
    "        match_rate = max(match_rate-0.05, 0.70)\n",
    "        tokenized = unique_matrix(synonyms)\n",
    "\n",
    "    return random.sample(augmented, num_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = word2vec_aug(train[train['target']==1]['reviews'].tolist(), 10000)\n",
    "augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['reviews'] = train['reviews'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')\n",
    "test['reviews'] = test['reviews'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','')\n",
    "\n",
    "train['reviews'] = train['reviews'].str.replace('^ +','')\n",
    "test['reviews'] = test['reviews'].str.replace('^ +','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "train_data = [ko_tokenize(review) for review in train['reviews'].tolist()]\n",
    "train_label = train['target'].tolist()\n",
    "test_data = [ko_tokenize(review) for review in test['reviews'].tolist()]\n",
    "\n",
    "num_aug = train['target'].value_counts().max()\n",
    "for rate in train['target'].unique():\n",
    "    reviews = train[train['target']==rate]['reviews'].tolist()\n",
    "    if len(reviews) == num_aug:\n",
    "        continue\n",
    "\n",
    "    augmented = word2vec_aug(reviews, num_aug)\n",
    "    train_data += augmented\n",
    "    train_label += [rate for _ in range(len(augmented))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'reviews':train_data,'target':train_label}).to_csv('data/tokenized1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(data={'target':train_label}, x='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500 17500 7500 7500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = \\\n",
    "    train_test_split(train_data, train_label, test_size=0.3,\n",
    "                        stratify=train_label, shuffle=True, random_state=0)\n",
    "\n",
    "print(len(train_X), len(train_y), len(val_X), len(val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embedding_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
    "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        max_len = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n",
      "훈련용 리뷰 개수 : 25000\n",
      "테스트용 리뷰 개수 : 25000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # 빈도수 상위 2만개의 단어만 사용\n",
    "max_len = 200  # 문장의 최대 길이\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
    "print('테스트용 리뷰 개수 : {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
    "num_heads = 2  # 어텐션 헤드의 수\n",
    "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
    "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
    "x = transformer_block(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=2, validation_data=(X_test, y_test))\n",
    "\n",
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 12978, 3409, 5926, 11988, 16, 16305, 5868, 8297, 13365, 5842, 6136, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_X['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_X['token_type_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_X['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, initializers, losses, optimizers, metrics, callbacks \n",
    "\n",
    "SEQ_LEN = 512 # 최대 token 개수 이상의 값으로 임의로 설정\n",
    "\n",
    "koelectra = ElectraModel.from_pretrained('monologg/koelectra-base-discriminator')\n",
    "\n",
    "input_token_ids   = layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_token_ids')   # tokens_tensor\n",
    "input_masks       = layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')       # masks_tensor\n",
    "input_segments    = layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segments')    # segments_tensor  \n",
    "\n",
    "koelectra_outputs = koelectra([input_token_ids, input_masks, input_segments]) \n",
    "# koelectra_outputs -> 0: 'last_hidden_state' & 1: 'pooler_output' (== applied GlobalAveragePooling1D on 'last_hidden_state')\n",
    "\n",
    "koelectra_outputs = koelectra_outputs[1]\n",
    "koelectra_outputs = layers.Dropout(0.2)(koelectra_outputs)\n",
    "final_output = layers.Dense(units=4, activation='softmax', kernel_initializer=initializers.TruncatedNormal(stddev=0.02), name=\"classifier\")(koelectra_outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_token_ids, input_masks, input_segments], \n",
    "                       outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = 'saved_models/'\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "\n",
    "# For custom models, we have to use \"save_weights_only = True\" (or we should implement a \"get_config\" method @ https://j.mp/3ltUibd) \n",
    "callback_checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path + 'koelectra_weight.h5', # 이번 실습에서 변경되었습니다\n",
    "                                                monitor='val_sparse_categorical_accuracy',\n",
    "                                                save_best_only=True, \n",
    "                                                save_weights_only = True, \n",
    "                                                verbose=1) \n",
    "                                                \n",
    "# Early-stopping for preventing the overfitting\n",
    "callback_earlystop = callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', \n",
    "                                             min_delta=0.0001, # the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "                                             patience=5) #  Number of epochs with no improvement after which training will be stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25분 가량 소요됩니다 (epochs를 4~5 정도로 주더라도 비슷한 수준으로 학습이 가능합니다)\n",
    "\n",
    "history = model.fit(train_X, train_y, validation_split=0.2,\n",
    "                    epochs=10, batch_size=100,\n",
    "                    verbose=1,\n",
    "                    callbacks=[callback_checkpoint, callback_earlystop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('mldl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86ae205601b6d906014fa7892090616f7e1469eb0aa86f06d2d1803a695f1eb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
